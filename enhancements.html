<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Latest Enhancements | MLOS Foundation</title>
    <meta name="description" content="Universal ONNX conversion and multi-type tensor support - Latest enhancements to MLOS">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    
    <style>
        :root {
            --color-primary: #0f172a;
            --color-secondary: #3b82f6;
            --color-accent: #06b6d4;
            --color-text: #1e293b;
            --color-text-muted: #64748b;
            --gradient-axon: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --gradient-core: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            --gradient-onnx: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: #2d3748;
            background: #f8f9fa;
        }

        /* Navigation - Consistent with index.html */
        .nav {
            background: rgba(255, 255, 255, 0.98);
            backdrop-filter: blur(10px);
            padding: 1rem 0;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            border-bottom: 1px solid #e2e8f0;
        }

        .nav-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: 800;
            color: var(--color-primary);
            text-decoration: none;
        }

        .logo span { color: var(--color-accent); }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
            align-items: center;
        }

        .nav-links a {
            text-decoration: none;
            color: var(--color-text);
            font-weight: 500;
            font-size: 0.95rem;
            transition: color 0.2s;
        }

        .nav-links a:hover { color: var(--color-secondary); }

        .nav-cta {
            background: var(--color-secondary);
            color: white !important;
            padding: 0.5rem 1rem;
            border-radius: 6px;
        }

        .nav-cta:hover { background: #2563eb; }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        @media (max-width: 768px) {
            .nav-links { display: none; }
        }

        .hero {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 8rem 0 4rem;
            text-align: center;
        }
        
        .hero h1 {
            font-size: 3rem;
            font-weight: 800;
            margin-bottom: 1rem;
        }
        
        .hero p {
            font-size: 1.25rem;
            opacity: 0.95;
            max-width: 700px;
            margin: 0 auto;
        }
        
        .badge {
            display: inline-block;
            background: rgba(255, 255, 255, 0.2);
            padding: 0.5rem 1rem;
            border-radius: 2rem;
            font-size: 0.9rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
        }
        
        .section {
            padding: 4rem 0;
        }
        
        .section-title {
            font-size: 2.5rem;
            font-weight: 700;
            text-align: center;
            margin-bottom: 3rem;
        }
        
        .enhancement-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }
        
        .enhancement-card {
            background: white;
            border-radius: 1rem;
            padding: 2rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
            transition: transform 0.3s, box-shadow 0.3s;
        }
        
        .enhancement-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
        }
        
        .enhancement-card h3 {
            font-size: 1.5rem;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .icon {
            font-size: 2rem;
        }
        
        .feature-list {
            list-style: none;
            margin-top: 1rem;
        }
        
        .feature-list li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
        }
        
        .feature-list li:before {
            content: "‚úÖ";
            position: absolute;
            left: 0;
        }
        
        .code-block {
            background: #1e293b;
            color: #e2e8f0;
            padding: 1.5rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            margin: 1.5rem 0;
        }
        
        .diagram-container {
            background: white;
            padding: 2rem;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
            margin: 3rem 0;
        }
        
        .diagram-container img {
            width: 100%;
            height: auto;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 2rem;
            margin-top: 2rem;
        }
        
        .stat-card {
            background: white;
            padding: 2rem;
            border-radius: 1rem;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
        }
        
        .stat-number {
            font-size: 3rem;
            font-weight: 800;
            background: var(--gradient-axon);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .stat-label {
            font-size: 1rem;
            color: #718096;
            margin-top: 0.5rem;
        }
        
        .cta-section {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 4rem 0;
            text-align: center;
            margin-top: 4rem;
        }
        
        .cta-button {
            display: inline-block;
            background: white;
            color: #f5576c;
            padding: 1rem 2rem;
            border-radius: 0.5rem;
            text-decoration: none;
            font-weight: 600;
            margin-top: 1.5rem;
            transition: transform 0.3s;
        }
        
        .cta-button:hover {
            transform: scale(1.05);
        }
        
        .gradient-text {
            background: var(--gradient-axon);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="nav">
        <div class="container">
            <div class="nav-content">
                <a href="index.html" class="logo">ml<span>OS</span></a>
                <ul class="nav-links">
                    <li><a href="architecture.html">Architecture</a></li>
                    <li><a href="ecosystem.html">Ecosystem</a></li>
                    <li><a href="models.html">Models</a></li>
                    <li><a href="runtime-modes.html">Runtime</a></li>
                    <li><a href="https://github.com/mlOS-foundation">GitHub</a></li>
                    <li><a href="index.html#getting-started" class="nav-cta">Get Started</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <section class="hero">
        <div class="container">
            <div class="badge">‚ú® v3.2.10-alpha + v3.1.4</div>
            <h1>Format-Agnostic Runtime<br/>Native LLM Support!</h1>
            <p>MLOS now runs models in their native format - GGUF models execute directly via llama.cpp, no conversion needed</p>
        </div>
    </section>
    
    <!-- Main Enhancements -->
    <section class="section">
        <div class="container">
            <h2 class="section-title">üöÄ Major Enhancements</h2>
            
            <div class="enhancement-grid">
                <!-- NEW: Format-Agnostic Runtime -->
                <div class="enhancement-card" style="border: 2px solid #667eea;">
                    <h3><span class="icon">üöÄ</span> NEW: Format-Agnostic Runtime</h3>
                    <p>Models run in their native format - no unnecessary conversions!</p>

                    <ul class="feature-list">
                        <li>GGUF: Native llama.cpp execution</li>
                        <li>ONNX: Built-in runtime</li>
                        <li>SafeTensors: Auto-convert</li>
                        <li>PyTorch: Auto-convert</li>
                        <li>Smart format detection</li>
                    </ul>

                    <div class="code-block">
# GGUF LLM - native execution!
axon install hf/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF@latest
# No conversion - runs directly via llama.cpp!</div>
                </div>

                <!-- Axon Enhancement -->
                <div class="enhancement-card">
                    <h3><span class="icon">‚ö°</span> Axon v3.1.4: Smart Detection</h3>
                    <p>Format-agnostic installation with extension + magic byte detection</p>

                    <ul class="feature-list">
                        <li>Auto-detect GGUF, ONNX, SafeTensors</li>
                        <li>Skip conversion when not needed</li>
                        <li>Magic byte validation</li>
                        <li>Fallback to ONNX conversion</li>
                        <li>LLM-ready installation</li>
                    </ul>

                    <div class="code-block">
# Smart format detection
axon install hf/gpt2@latest        # ONNX
axon install hf/TheBloke/...@latest # GGUF</div>
                </div>
                
                <!-- Core Enhancement -->
                <div class="enhancement-card">
                    <h3><span class="icon">üß†</span> Core v5.2.0: LLM Plugin</h3>
                    <p>Native GGUF execution via llama.cpp backend</p>

                    <ul class="feature-list">
                        <li>GGUF runtime plugin (llama.cpp)</li>
                        <li>TinyLlama, Phi-2, Qwen support</li>
                        <li>Text generation API</li>
                        <li>4-bit quantization aware</li>
                        <li>Streaming responses</li>
                        <li>Multi-plugin architecture</li>
                    </ul>

                    <div class="code-block">
# LLM text generation
curl -X POST /models/tinyllama/inference \
  -d '{"prompt": "What is ML?",
       "max_tokens": 64}'</div>
                </div>
                
                <!-- Integration -->
                <div class="enhancement-card">
                    <h3><span class="icon">üîó</span> Seamless Integration</h3>
                    <p>Complete E2E workflow from any repository to kernel-level inference</p>
                    
                    <ul class="feature-list">
                        <li>Zero API changes</li>
                        <li>Backward compatible</li>
                        <li>~2-8ms inference</li>
                        <li>Dynamic shapes</li>
                        <li>Automatic type detection</li>
                        <li>Multi-strategy fallbacks</li>
                    </ul>
                    
                    <div class="code-block">
# Complete workflow
axon install hf/gpt2@latest
axon register hf/gpt2@latest
# Ready for inference!</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Architecture Diagram -->
    <section class="section" style="background: white;">
        <div class="container">
            <h2 class="section-title">üìê End-to-End Architecture</h2>
            <div class="diagram-container">
                <img src="e2e-architecture.svg" alt="MLOS E2E Architecture" />
            </div>
        </div>
    </section>
    
    <!-- Statistics -->
    <section class="section">
        <div class="container">
            <h2 class="section-title">üìä By the Numbers</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">2</div>
                    <div class="stat-label">Runtime<br/>Plugins</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">4</div>
                    <div class="stat-label">Supported<br/>Formats</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">0</div>
                    <div class="stat-label">GGUF<br/>Conversion Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">100K+</div>
                    <div class="stat-label">Models<br/>Available</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">4-bit</div>
                    <div class="stat-label">LLM<br/>Quantization</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">100%</div>
                    <div class="stat-label">Backward<br/>Compatible</div>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Technical Deep Dive -->
    <section class="section" style="background: white;">
        <div class="container">
            <h2 class="section-title">üî¨ Technical Highlights</h2>

            <div class="enhancement-card" style="max-width: 800px; margin: 0 auto;">
                <h3>Format-Agnostic Runtime: Why It Matters</h3>
                <p>Traditional ML pipelines convert everything to ONNX - but this wastes time and loses optimizations for formats like GGUF:</p>

                <div class="code-block">
Traditional (Always Convert):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GGUF LLM ‚îÇ -> ‚îÇ Convert ONNX ‚îÇ -> ‚îÇ ONNX Runtime ‚îÇ  ‚ùå Minutes, quality loss
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  (slow!)     ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

MLOS Format-Agnostic:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GGUF LLM ‚îÇ -> ‚îÇ llama.cpp    ‚îÇ  ‚úÖ Instant, native quality
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  (direct!)   ‚îÇ</div>

                <h3 style="margin-top: 2rem;">Smart Format Detection (Axon v3.1.4)</h3>
                <p>Axon uses a multi-layer detection strategy:</p>

                <div class="code-block">
1. File Extension Detection:
   .gguf      ‚Üí GGUF format (llama.cpp)
   .onnx      ‚Üí ONNX format (built-in)
   .safetensors ‚Üí SafeTensors (convert to ONNX)
   .pt/.pth   ‚Üí PyTorch (convert to ONNX)

2. Magic Byte Validation:
   "GGUF"     ‚Üí GGUF confirmed
   PK (ZIP)   ‚Üí PyTorch ZIP archive
   0x80       ‚Üí Pickle format

3. IsExecutionReady() Check:
   true  ‚Üí Skip conversion, use native runtime
   false ‚Üí Convert to ONNX</div>

                <h3 style="margin-top: 2rem;">Multi-Plugin Architecture (Core v5.2.0)</h3>
                <p>MLOS Core routes models to the optimal runtime plugin:</p>

                <div class="code-block">
// Plugin Registry
PluginRegistry:
  ‚îú‚îÄ‚îÄ ONNX Runtime Plugin (built-in)
  ‚îÇ   ‚îî‚îÄ‚îÄ Handles: .onnx files
  ‚îÇ
  ‚îî‚îÄ‚îÄ GGUF/llama.cpp Plugin (new!)
      ‚îî‚îÄ‚îÄ Handles: .gguf files
          ‚îú‚îÄ‚îÄ TinyLlama-1.1B (Q4_K_M)
          ‚îú‚îÄ‚îÄ Phi-2 (Q4_K_M)
          ‚îî‚îÄ‚îÄ Qwen2-0.5B (Q4_K_M)</div>

                <h3 style="margin-top: 2rem;">Zero-Cost Abstraction</h3>
                <p>The plugin architecture leverages the existing generic <code>void*</code> API - proving the architecture was designed right from the start. Both ONNX and GGUF plugins use the same SMI interface!</p>
            </div>
        </div>
    </section>
    
    <!-- Tested Models -->
    <section class="section">
        <div class="container">
            <h2 class="section-title">‚úÖ Tested & Verified</h2>

            <div class="enhancement-grid">
                <div class="enhancement-card" style="border: 2px solid #48bb78;">
                    <h3>ü¶ô LLM Models (GGUF)</h3>
                    <ul class="feature-list">
                        <li>TinyLlama 1.1B (Q4_K_M)</li>
                        <li>Phi-2 2.7B (Q4_K_M)</li>
                        <li>Qwen2 0.5B (Q4_K_M)</li>
                    </ul>
                    <p style="margin-top: 1rem; color: #48bb78; font-weight: 600;">Status: ‚úÖ Native GGUF Execution</p>
                </div>

                <div class="enhancement-card">
                    <h3>ü§ó NLP Models (ONNX)</h3>
                    <ul class="feature-list">
                        <li>GPT-2 (DistilGPT-2)</li>
                        <li>BERT (base-uncased)</li>
                        <li>RoBERTa</li>
                        <li>T5 (encoder-decoder)</li>
                        <li>DistilBERT</li>
                        <li>ALBERT</li>
                    </ul>
                    <p style="margin-top: 1rem; color: #48bb78; font-weight: 600;">Status: ‚úÖ Passing</p>
                </div>

                <div class="enhancement-card">
                    <h3>üñºÔ∏è Vision Models (ONNX)</h3>
                    <ul class="feature-list">
                        <li>ResNet-50</li>
                        <li>ViT (Vision Transformer)</li>
                        <li>ConvNeXt</li>
                        <li>MobileNetV2</li>
                        <li>DeiT</li>
                        <li>EfficientNet</li>
                    </ul>
                    <p style="margin-top: 1rem; color: #48bb78; font-weight: 600;">Status: ‚úÖ Passing</p>
                </div>

                <div class="enhancement-card">
                    <h3>üé® Multi-Modal (ONNX)</h3>
                    <ul class="feature-list">
                        <li>CLIP (text + image)</li>
                        <li>Sentence-Transformers</li>
                    </ul>
                    <p style="margin-top: 1rem; color: #48bb78; font-weight: 600;">Status: ‚úÖ Passing</p>
                </div>
            </div>
        </div>
    </section>
    
    <!-- CTA -->
    <section class="cta-section">
        <div class="container">
            <h2 style="font-size: 2.5rem; margin-bottom: 1rem;">Ready to Try MLOS?</h2>
            <p style="font-size: 1.25rem; opacity: 0.95; max-width: 600px; margin: 0 auto;">
                Start running models from any repository with kernel-level performance today
            </p>
            <a href="https://github.com/mlos-foundation" class="cta-button">View on GitHub ‚Üí</a>
        </div>
    </section>
    
    <footer style="background: #1e293b; color: white; padding: 2rem 0; text-align: center;">
        <div class="container">
            <p>&copy; 2025 MLOS Foundation. Open Source under MIT License.</p>
        </div>
    </footer>
</body>
</html>

